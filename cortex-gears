#!/usr/bin/perl
# /=====================================================================\ #
# |  CorTeX Framework                                                   | #
# | Gears - Scheduler and Gearman Client                                | #
# |=====================================================================| #
# | Part of the LaMaPUn project: https://trac.kwarc.info/lamapun/       | #
# |  Research software, produced as part of work done by:               | #
# |  the KWARC group at Jacobs University                               | #
# | Copyright (c) 2012                                                  | #
# | Released under the GNU Public License                               | #
# |---------------------------------------------------------------------| #
# | Deyan Ginev <d.ginev@jacobs-university.de>                  #_#     | #
# | http://kwarc.info/people/dginev                            (o o)    | #
# \=========================================================ooo==U==ooo=/ #
use strict;
use warnings;
use Encode;

use File::Basename;
my ($FILE_BASE,$libdir);
BEGIN {
    $FILE_BASE = dirname(__FILE__);
    $libdir = $FILE_BASE."/lib"; }
if (-d $libdir) {
  use lib $libdir; }

use CorTeX::Util::DB_File_Utils qw(db_file_connect db_file_disconnect);

## Plan of action:
# 0. Add all default services (if necessary)
my $default_service_ids = register_defaults();
# 1. Spawn/fork local workers (lib/CorTeX/Service/*.json)
spawn_workers($default_service_ids);
#    # workers = 5 x ( # cpus ) x (# local services)
# 2. Start event loop on the task queue
# 2.1. If no queued tasks - sleep 60
# 2.2. Otherwise, add jobs with AnyEvent::Gearman


{
  local $SIG{'INT'} = \&stop_all; # Interrupt handler
  local $SIG{'HUP'} = \&stop_all; # Apache Hangup handler
  local $SIG{'KILL'} = \&stop_all; # Just good-old KILL handler

  my ($MAIN_REPOS,$META_GRAPH,$BUILD_SYSTEM_URL) = @ARGV;
  my $Cache={ children=> [] };  # Mock Object ?

  while (1) {
    my $init_backend_needed = 0;
    my $db_handle = db_file_connect;
    my $sesame_url = $db_handle->{sesame_url};
    my $exist_url = $db_handle->{exist_url};
    $Cache->{proxy_url} = $db_handle->{proxy_url};
    $Cache->{converters} = [ split("\n", $db_handle->{converter_urls}||'') ];
    db_file_disconnect($db_handle);
    if ((! defined $Cache->{exist_url}) || ($Cache->{exist_url} ne $exist_url)) {
      $init_backend_needed = 1;
      $Cache->{exist_url} = $exist_url;
    }
    if ((! defined $Cache->{sesame_url}) || ($Cache->{sesame_url} ne $sesame_url)) {
      $init_backend_needed = 1;
      $Cache->{sesame_url} = $sesame_url;
    }
    if ($init_backend_needed) {
      $Cache->{backend} = CorTeX::Backend->new(exist_url=>$exist_url,sesame_url=>$sesame_url);
    }
    my $sesame = $Cache->{backend}->sesame;

    # Is there a repository we can work with?
    my $repo_size = $sesame->repository_size($MAIN_REPOS);
    if ($repo_size && ($repo_size != -1)) {
      # Anything left in limbo? (i.e. priority -1). If so, update it to 1.
      $sesame->mark_limbo_entries_queued({graph=>$META_GRAPH,repository=>$MAIN_REPOS});
      # Check if unprocessed entries remain to be converted
      if ($sesame->count_entries($MAIN_REPOS,'queued')) {
        # Also, retrieve corpus type, so that we optimize for single-file corpora (ZBL, PlanetMath):
        my $entry_type = $sesame->get_entry_type($MAIN_REPOS);
        $Cache->{entry_type} = $entry_type;
        # Boot up clients/workers, if none are present:
        spawn_workers($Cache) unless (@{$Cache->{workers}} > 0);
        spawn_clients($Cache) unless (@{$Cache->{clients}} > 0);
        # Otherwise, we still need to process some files... so nothing extra to do
      } else {
        # Everything seems done!
        # Stop all converters after their jobs are done and sleep
        stop_clients($Cache);
      }
    }
    else {
      stop_clients($Cache);
    }

    sleep 60;
  }
  
  use Unix::Processors;
  my $processor_multiplier = Unix::Processors->new->max_online;
  sub spawn_workers {
    my $dbfile = db_file_connect;
    $dbfile->{gearman_urls};


  }

  sub spawn_clients {
    my ($cache) = @_;
    my @converters = @{$cache->{converters}};
    my $query_size = scalar(@converters);
    while (@converters) {
      # Fork a job for each one!
      my $c = shift @converters;
      my $pid = fork();
      if ($pid == 0) {
        use CorTeX::Gears::Builder;
        my $gearman_client = CorTeX::Gears::Builder->new(main_repos=>$MAIN_REPOS,
                                                         meta_graph=>$META_GRAPH,
                                                         build_system_url=>$BUILD_SYSTEM_URL,
                                                         backend=>$Cache->{backend},
                                                         proxy_url=>$Cache->{proxy_url},
                                                         entry_type=>$Cache->{entry_type},
                                                         query_size=>$query_size);
        $gearman_client->start;
      } else {
        print STDERR "Started process $pid\n";
        push @{$cache->{clients}}, $pid;
      }
    }
  }

  sub stop_all {
    stop_clients($Cache);
    exit 0; }

  sub stop_clients {
    my ($cache) = @_;
    stop_cron_job($_) foreach @{$cache->{clients}};
    $cache->{clients} = []; }

  sub stop_cron_job {
    my ($pid) = @_;
    # Send a SIGINT to the cron job
    kill 2, $pid;
    waitpid($pid,0); }

  sub register_defaults {
    our ($INSTALLDIR) = grep(-d $_, map("$_/CorTeX", @INC));
    my $services_dir = $INSTALLDIR."/Service";
    opendir(my $dh, $services_dir)
     || die "can't opendir $services_dir: $!";
    my @default_service_descriptions = grep { /\.json$/ && -f "$services_dir/$_" }
    readdir($dh);
    closedir $dh;
    my @default_service_ids = ();
    if (@default_service_descriptions) {
      use File::Slurp;
      use JSON::XS qw(decode_json);
      use Data::Dumper;
      my $dbhandle = db_file_connect; 
      my $backend = CorTeX::Backend->new(%$dbhandle);
      my $current_services = $backend->taskdb->current_services;
      db_file_disconnect($dbhandle);
      foreach my $service_file(@default_service_descriptions) {
        my $service_description = decode_json(read_file( "$services_dir/$service_file" ));
        my ($id) =  split(/.json/,$service_file);
        push @default_service_ids, $id;
        my $name = $service_description->{name};
        $service_description->{id} = $id;
        unless (grep {$name eq $_} @$current_services) {
          $backend->taskdb->register_service(%$service_description);
        }
      }
    }
    return \@default_service_ids; # We want to boot workers for these
  }
}

__END__

=pod 

=head1 NAME

C<cortex-gears> - Scheduler of the CorTeX framework

=head1 SYNOPSIS

TODO

=head1 DESCRIPTION

TODO

=head1 Gearman Installation

Under Debian-based systems:
 sudo apt-get install
   gearman
   gearman-job-server
   gearman-tools
   gearman-server
   mod-gearman-tools
   libgearman-client-async-perl
   libmodule-install-xsutil-perl
   libgearman-dev

   cpan Gearman::XS::Client
   cpan Gearman::XS::Worker
=head1 AUTHOR

Deyan Ginev <d.ginev@jacobs-university.de>

=head1 COPYRIGHT

 Research software, produced as part of work done by 
 the KWARC group at Jacobs University Bremen.
 Released under the GNU Public License

=cut
